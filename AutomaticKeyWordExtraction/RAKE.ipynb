{
 "metadata": {
  "name": "",
  "signature": "sha256:d354fcf2cc287fb24014c75c7318f181d858d73cdedf54af300ad60d5e2c264f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "RAKE algorithm (Patented by Google 2012)   \n",
      "Original paper by Stuart Rose, Dave Engel, Nick Cramer and Wendy Cowley (2010)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is just a demo notebook. I have heavily borrowed from https://github.com/zelandiya/RAKE-tutorial/blob/master/rake.py"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import io, os,re\n",
      "import nltk, sklearn\n",
      "import itertools\n",
      "import operator\n",
      "from operator import itemgetter\n",
      "import networkx as nx\n",
      "from collections import defaultdict\n",
      "from nltk.corpus import stopwords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Build a stopword regex"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_stop_word_regex(stop_word_list):\n",
      "    stop_word_regex_list = []\n",
      "    for word in stop_word_list:\n",
      "        word_regex = '\\\\b' + word + '\\\\b'\n",
      "        stop_word_regex_list.append(word_regex)\n",
      "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
      "    return stop_word_pattern"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some utility functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Function that checks if a string is a number \n",
      "def is_number(s):\n",
      "    try:\n",
      "        float(s) if '.' in s else int(s)\n",
      "        return True\n",
      "    except ValueError:\n",
      "        return False\n",
      "  \n",
      "# check if the phrase contains terms that are digits. Ignore such phrases \n",
      "def is_acceptable(phrase, min_char_length, max_words_length=1):\n",
      "    # a phrase must have a min length in characters\n",
      "    if len(phrase) < min_char_length:\n",
      "        return 0\n",
      "    \n",
      "    #a phrase must have a max number of words\n",
      "    words = phrase.split()\n",
      "    if len(words) > max_words_length:\n",
      "        return 0\n",
      "    \n",
      "    digits = 0\n",
      "    alpha = 0\n",
      "    for i in range(0, len(phrase)):\n",
      "        if phrase[i].isdigit():\n",
      "            digits += 1\n",
      "        elif phrase[i].isalpha():\n",
      "            alpha += 1\n",
      "    # a phrase must have at least one alpha character\n",
      "    if alpha == 0:\n",
      "        return 0\n",
      "    # a phrase must have more alpha than digits characters\n",
      "    if digits > alpha:\n",
      "        return 0\n",
      "    return 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functions that create candidate keywords using stopwords, compute word scores and phrase scores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Splits whenever we hit a match is a stopword and create a phrase list\n",
      "def generate_candidate_keywords(sentence_list, stopword_pattern, min_char_length=1):\n",
      "    phrase_list = []\n",
      "    for s in sentence_list:\n",
      "        tmp = re.sub(stopword_pattern, '|', s.strip())\n",
      "        phrases = tmp.split(\"|\")\n",
      "        for phrase in phrases:\n",
      "            phrase = phrase.strip().lower()\n",
      "            if phrase != \"\" and is_acceptable(phrase, min_char_length):\n",
      "                phrase_list.append(phrase)\n",
      "    return phrase_list\n",
      "\n",
      "# For each unique word in the phraseList compute its degree and frequency and score\n",
      "def calculate_word_scores(phraseList):\n",
      "    word_frequency = {}\n",
      "    word_degree = {}\n",
      "    for phrase in phraseList:\n",
      "        word_list = separate_words(phrase, 0)\n",
      "        word_list_length = len(word_list)\n",
      "        word_list_degree = word_list_length - 1\n",
      "        #if word_list_degree > 3: word_list_degree = 3 #exp.\n",
      "        for word in word_list:\n",
      "            word_frequency.setdefault(word, 0)\n",
      "            word_frequency[word] += 1\n",
      "            word_degree.setdefault(word, 0)\n",
      "            word_degree[word] += word_list_degree  #orig.\n",
      "            #word_degree[word] += 1/(word_list_length*1.0) #exp.\n",
      "    for item in word_frequency:\n",
      "        word_degree[item] = word_degree[item] + word_frequency[item]\n",
      "\n",
      "    # Calculate Word scores = deg(w)/frew(w)\n",
      "    word_score = {}\n",
      "    for item in word_frequency:\n",
      "        word_score.setdefault(item, 0)\n",
      "        word_score[item] = word_degree[item] / (word_frequency[item] * 1.0)  #orig.\n",
      "    #word_score[item] = word_frequency[item]/(word_degree[item] * 1.0) #exp.\n",
      "    return word_score\n",
      "\n",
      "# Generate scores of phrases as a sum of word scores of the words found in that phrase\n",
      "def generate_candidate_keyword_scores(phrase_list, word_score, min_keyword_frequency=1):\n",
      "    keyword_candidates = {}\n",
      "\n",
      "    for phrase in phrase_list:\n",
      "        if min_keyword_frequency > 1:\n",
      "            if phrase_list.count(phrase) < min_keyword_frequency:\n",
      "                continue\n",
      "        keyword_candidates.setdefault(phrase, 0)\n",
      "        word_list = separate_words(phrase, 0)\n",
      "        candidate_score = 0\n",
      "        for word in word_list:\n",
      "            candidate_score += word_score[word]\n",
      "        keyword_candidates[phrase] = candidate_score\n",
      "    return keyword_candidates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some preprocessing functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Split a text into sentences. One could also use the sentence tokenizer\n",
      "def split_sentences(text):\n",
      "    \"\"\"\n",
      "    Utility function to return a list of sentences.\n",
      "    @param text The text that must be split in to sentences.\n",
      "    \"\"\"\n",
      "    sentence_delimiters = re.compile(u'[\\\\[\\\\]\\n.!?;:\\t\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]')\n",
      "    sentences = sentence_delimiters.split(text)\n",
      "    return sentences\n",
      "\n",
      "# Separate words based on space and other word delimiters\n",
      "def separate_words(text, min_word_return_size):\n",
      "    \"\"\"\n",
      "    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n",
      "    @param text The text that must be split in to words.\n",
      "    @param min_word_return_size The minimum no of characters a word must have to be included.\n",
      "    \"\"\"\n",
      "    splitter = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n",
      "    words = []\n",
      "    for single_word in splitter.split(text):\n",
      "        current_word = single_word.strip().lower()\n",
      "        #leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n",
      "        if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):\n",
      "            words.append(current_word)\n",
      "    return words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text  = '''In this paper, we introduce TextRank, a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications. In particular, we propose two innovative unsupervised methods for keyword and sentence extraction, and show that the results obtained compare favorably with previously published results on established benchmarks.'''\n",
      "text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "'In this paper, we introduce TextRank, a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications. In particular, we propose two innovative unsupervised methods for keyword and sentence extraction, and show that the results obtained compare favorably with previously published results on established benchmarks.'"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordTokens = nltk.word_tokenize(text)\n",
      "wordTokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "['In',\n",
        " 'this',\n",
        " 'paper',\n",
        " ',',\n",
        " 'we',\n",
        " 'introduce',\n",
        " 'TextRank',\n",
        " ',',\n",
        " 'a',\n",
        " 'graph-based',\n",
        " 'ranking',\n",
        " 'model',\n",
        " 'for',\n",
        " 'text',\n",
        " 'processing',\n",
        " ',',\n",
        " 'and',\n",
        " 'show',\n",
        " 'how',\n",
        " 'this',\n",
        " 'model',\n",
        " 'can',\n",
        " 'be',\n",
        " 'successfully',\n",
        " 'used',\n",
        " 'in',\n",
        " 'natural',\n",
        " 'language',\n",
        " 'applications',\n",
        " '.',\n",
        " 'In',\n",
        " 'particular',\n",
        " ',',\n",
        " 'we',\n",
        " 'propose',\n",
        " 'two',\n",
        " 'innovative',\n",
        " 'unsupervised',\n",
        " 'methods',\n",
        " 'for',\n",
        " 'keyword',\n",
        " 'and',\n",
        " 'sentence',\n",
        " 'extraction',\n",
        " ',',\n",
        " 'and',\n",
        " 'show',\n",
        " 'that',\n",
        " 'the',\n",
        " 'results',\n",
        " 'obtained',\n",
        " 'compare',\n",
        " 'favorably',\n",
        " 'with',\n",
        " 'previously',\n",
        " 'published',\n",
        " 'results',\n",
        " 'on',\n",
        " 'established',\n",
        " 'benchmarks',\n",
        " '.']"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence_delimiters = re.compile(u'[\\\\[\\\\]\\n.!?,;:\\t\\\\-\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]')\n",
      "stop = stopwords.words('english')\n",
      "stopword_pattern = build_stop_word_regex(stop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentence_list = split_sentences(text)\n",
      "sentence_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "['In this paper, we introduce TextRank, a graph-based ranking model for text processing, and show how this model can be successfully used in natural language applications',\n",
        " ' In particular, we propose two innovative unsupervised methods for keyword and sentence extraction, and show that the results obtained compare favorably with previously published results on established benchmarks',\n",
        " '']"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrase_list = generate_candidate_keywords(sentence_list, stopword_pattern, 1)\n",
      "phrase_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "['paper,',\n",
        " 'introduce textrank,',\n",
        " 'graph-based ranking model',\n",
        " 'text processing,',\n",
        " 'show',\n",
        " 'model',\n",
        " 'successfully used',\n",
        " 'natural language applications',\n",
        " 'particular,',\n",
        " 'propose two innovative unsupervised methods',\n",
        " 'keyword',\n",
        " 'sentence extraction,',\n",
        " 'show',\n",
        " 'results obtained compare favorably',\n",
        " 'previously published results',\n",
        " 'established benchmarks']"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_scores = calculate_word_scores(phrase_list)\n",
      "word_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "{'applications': 3.0,\n",
        " 'benchmarks': 2.0,\n",
        " 'compare': 4.0,\n",
        " 'established': 2.0,\n",
        " 'extraction': 2.0,\n",
        " 'favorably': 4.0,\n",
        " 'graph-based': 3.0,\n",
        " 'innovative': 5.0,\n",
        " 'introduce': 2.0,\n",
        " 'keyword': 1.0,\n",
        " 'language': 3.0,\n",
        " 'methods': 5.0,\n",
        " 'model': 2.0,\n",
        " 'natural': 3.0,\n",
        " 'obtained': 4.0,\n",
        " 'paper': 1.0,\n",
        " 'particular': 1.0,\n",
        " 'previously': 3.0,\n",
        " 'processing': 2.0,\n",
        " 'propose': 5.0,\n",
        " 'published': 3.0,\n",
        " 'ranking': 3.0,\n",
        " 'results': 3.5,\n",
        " 'sentence': 2.0,\n",
        " 'show': 1.0,\n",
        " 'successfully': 2.0,\n",
        " 'text': 2.0,\n",
        " 'textrank': 2.0,\n",
        " 'two': 5.0,\n",
        " 'unsupervised': 5.0,\n",
        " 'used': 2.0}"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores, 1)\n",
      "keyword_candidates"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "{'established benchmarks': 4.0,\n",
        " 'graph-based ranking model': 8.0,\n",
        " 'introduce textrank,': 4.0,\n",
        " 'keyword': 1.0,\n",
        " 'model': 2.0,\n",
        " 'natural language applications': 9.0,\n",
        " 'paper,': 1.0,\n",
        " 'particular,': 1.0,\n",
        " 'previously published results': 9.5,\n",
        " 'propose two innovative unsupervised methods': 25.0,\n",
        " 'results obtained compare favorably': 15.5,\n",
        " 'sentence extraction,': 4.0,\n",
        " 'show': 1.0,\n",
        " 'successfully used': 4.0,\n",
        " 'text processing,': 4.0}"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_keywords = sorted(keyword_candidates.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "sorted_keywords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "[('propose two innovative unsupervised methods', 25.0),\n",
        " ('results obtained compare favorably', 15.5),\n",
        " ('previously published results', 9.5),\n",
        " ('natural language applications', 9.0),\n",
        " ('graph-based ranking model', 8.0),\n",
        " ('sentence extraction,', 4.0),\n",
        " ('established benchmarks', 4.0),\n",
        " ('introduce textrank,', 4.0),\n",
        " ('successfully used', 4.0),\n",
        " ('text processing,', 4.0),\n",
        " ('model', 2.0),\n",
        " ('keyword', 1.0),\n",
        " ('show', 1.0),\n",
        " ('paper,', 1.0),\n",
        " ('particular,', 1.0)]"
       ]
      }
     ],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}